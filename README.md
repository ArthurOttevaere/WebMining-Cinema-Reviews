# ğŸ¬ Projet Web Mining : Analyse des Critiques de CinÃ©ma

**Cours :** MLSMM2153 - Web Mining (2025-2026)  
**Professeurs :** Corentin Vande Kerckhove & Sylvain Courtain  
**Sujet 4 :** Analyse des critiques culturelles sur des blogs (CinÃ©ma)

---

## ğŸ‘¥ L'Ã‰quipe

* **Arthur Ottevaere**
* **Mohamed Amine El Mohicine**
* **Lenny Andry**

---

## ğŸ“– Contexte et Objectifs

Ce projet a pour but d'analyser les critiques cinÃ©matographiques se trouvant sur des blogs en ligne. Dans ce projet, nous collectons et analysons de nombreuses critiques provenant de trois blogs cinÃ©matographiques anglophones distincts afin d'identifier des tendances sÃ©mantiques et structurelles.

Le projet suit le mÃªme cheminement que le cours de Web Mining, Ã  savoir :

1. **Collecte de donnÃ©es (Scraping) :** RÃ©cupÃ©ration automatique de corpus massifs (textes, notes, mÃ©tadonnÃ©es, casting).
2. **Text Mining :** A complÃ©ter quand nous arriverons Ã  cette Ã©tape.
3. **Link Analysis :** A complÃ©ter quand nous arriverons Ã  cette Ã©tape.

---

## ğŸ“‚ Structure du Projet

L'architecture respecte la sÃ©paration entre code source, donnÃ©es brutes et rÃ©sultats. Dans le but de faciliter la rÃ©plication des analyses.

```text
.
â”œâ”€â”€ src/                    # Code source Python
â”‚   â”œâ”€â”€ scraping            # Scripts de collecte des donnÃ©es (RogerEbert)
â”‚   â”œâ”€â”€ text_mining         # Scripts de transformation et d'analyse du contenu textuel des critiques
â”‚   â”œâ”€â”€ link_analysis       # Scripts de construction du graph et d'analyses des liens
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # DonnÃ©es brutes issues du scraping, text-mining et link-analysis (.csv/.xlsx)
â”‚   â”‚                       # Note : Ces fichiers ne sont pas versionnÃ©s sur GitHub (via .gitignore)
â”‚   â””â”€â”€ processed/          # DonnÃ©es nettoyÃ©es prÃªtes pour l'analyse
â”‚
â”œâ”€â”€ results/                # Graphiques, visualisations et rapports
â”œâ”€â”€ .gitignore              # Configuration des fichiers exclus (env, donnÃ©es lourdes)
â”œâ”€â”€ requirements.txt        # Liste des dÃ©pendances Python nÃ©cessaires
â””â”€â”€ README.md               # Documentation du projet
```

---

## ğŸš€ Guide d'Utilisation (Pipeline)

### 1. Installation

Assurez-vous d'avoir Python 3.9+ installÃ©. Clonez le repo et installez les dÃ©pendances :

```Bash
git clone https://github.com/ArthurOttevaere/WebMining-Cinema-Reviews.git
cd WebMining-Cinema-Reviews
pip install -r requirements.txt
```

### 2. ExÃ©cution des analyses

L'ensemble du pipeline (Scraping, Text mining et Link analysis) est orchestrÃ©e par un scrpit unique afin d'assurer une meilleure rÃ©plicabilitÃ©. Alors, pour lancer l'analyse complÃ¨te, il suffit d'entrer la commande suivante dans votre terminal :

```Bash
python main.py
```

Ce script exÃ©cute, en arriÃ¨re plan, les Ã©tapes suivantes :

* **Chargement des donnÃ©es :** Par dÃ©faut, le script charge le dataset fourni `data/processed/reviews_final_900.csv` pour Ã©viter une nouvelle collecte longue des donnÃ©es. Cela permet Ã©galement d'obtenir les mÃªmes rÃ©sultats que ceux illustrÃ©s dans le rapport et dans l'ensemble de l'analyse.

* **Text mining :** Nettoyage, vectorisation TF-IDF et clustering des critiques cinÃ©matographiques. Des visuels relatifs Ã  l'analyse sÃ©mantique apparaitront au lancement du code.

* **Construction du graphe :** GÃ©nÃ¨re des noeuds et des arrÃªtes sur base de la similaritÃ© cosinus. Ces "Nodes" et "Edges" sont directement calculÃ©es via le corpus de donnÃ©es scrapÃ© (`data/processed/reviews_final_900.csv)`.

* **Link analysis :** Calcul des mÃ©triques avancÃ©es (CentralitÃ©, PareRank, etc.).

### **âš ï¸ Note importante concernant le Scraping (`RUN_SCRAPER = False`)**

Par dÃ©faut, la collecte de nouvelles donnÃ©es est dÃ©sactivÃ©e pour garantir la **stricte rÃ©plicabilitÃ© des rÃ©sultats** prÃ©sentÃ©s dans notre rapport.

Bien que le module de scraping soit complet et fonctionnel (importÃ© via `src.scraping`), nous vous recommandons vivement de **ne pas passer cette variable Ã  `True`**, car :

1. **CohÃ©rence :** Le site *RogerEbert.com* Ã©tant dynamique, une nouvelle collecte modifierait le corpus. Les clusters et mÃ©triques de graphe divergeraient alors de ceux analysÃ©s dans le PDF rendu.

2. **Performance :** L'analyse s'exÃ©cute ici instantanÃ©ment sur le jeu de donnÃ©es figÃ© (`reviews_final_900.csv`), alors qu'un nouveau scraping prendrait un temps plus consÃ©quent.

Le code de scraping est inclus dans le projet Ã  des fins de dÃ©monstration mÃ©thodologique et de vÃ©rification technique uniquement.

---

## ğŸ§  MÃ©thodologie et Concepts ClÃ©s

### Text Mining

La phase de text mining repose sur un pipeline complet de traitement linguistique et de modÃ©lisation vectorielle appliquÃ© aux critiques collectÃ©es. AprÃ¨s un nettoyage systÃ©matique du texte, les critiques ont Ã©tÃ© tokenisÃ©es, lemmatisÃ©es et filtrÃ©es Ã  lâ€™aide de critÃ¨res linguistiques et statistiques (stopwords, noms propres, frÃ©quence documentaire). Le corpus ainsi normalisÃ© a Ã©tÃ© reprÃ©sentÃ© sous forme de vecteurs TF-IDF intÃ©grant unigrams et bigrams, puis soumis Ã  une rÃ©duction dimensionnelle par SVD et Ã  une normalisation L2. Cette reprÃ©sentation permet de mesurer efficacement la similaritÃ© sÃ©mantique entre critiques via la similaritÃ© cosinus.

### Link Analysis (Approche Matricielle)

Contrairement aux approches classiques utilisant des librairies haut niveau, nous avons implÃ©mentÃ© les mesures de centralitÃ© via les concepts d'algÃ¨bre linÃ©aire et de calcul matriciel, tout deux abordÃ©s lors des cours thÃ©oriques :

* **CentralitÃ© de DegrÃ© :** CalculÃ©e via la matrice d'adjacence.

* **PageRank :** ImplÃ©mentÃ© par la mÃ©thode des puissances (Power Iteration).

* **Information Centrality :** CalculÃ©e Ã  partir de la Pseudo-Inverse du Laplacien (L +) pour identifier les nÅ“uds ponts.

* **Closeness, Eccentricity & Shortest Path :** BasÃ©s sur l'algorithme de Floyd-Warshall.

* **DiamÃ¨tre et rayon du graphe :** CalculÃ©s sur base de ..., ils nous renseigne sur la santÃ© globale du graphe.

* **Partitionnement spectral :** GrÃ¢ce Ã  une coupe du graphe en deux, il renseigne sur la cohÃ©sion interne des groupes, relativement Ã  leur dissociation les uns des autres.

---

## ğŸ“Š AperÃ§u des RÃ©sultats

### Visualisation Gephi

![/Users/arthurottevaere/Downloads/605446336_1517578152628690_6745418421955372632_n.png]
*LÃ©gende* : Les couleurs reprÃ©sentent les thÃ¨mes (Clusters) identifiÃ©s par TF-IDF.

### Top Films (Link Analysis)

Voici un extrait des films les plus influents identifiÃ©s par nos algorithmes : Mettre ici une capture d'Ã©cran ou un petit tableau du rendu Tabulate.
