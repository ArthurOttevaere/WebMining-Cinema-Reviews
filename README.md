# ğŸ¬ Projet Web Mining : Analyse des Critiques de CinÃ©ma

**Cours :** MLSMM2153 - Web Mining (2025-2026)  
**Professeurs :** Corentin Vande Kerckhove & Sylvain Courtain  
**Sujet 4 :** Analyse des critiques culturelles sur des blogs (CinÃ©ma)

---

## ğŸ‘¥ L'Ã‰quipe

* **Arthur Ottevaere**
* **Mohamed Amine El Mohicine**
* **Lenny Andry**

---

## ğŸ“– Contexte et Objectifs

Ce projet a pour but d'analyser les critiques cinÃ©matographiques se trouvant sur des blogs en ligne. Dans ce projet, nous collectons et analysons de nombreuses critiques provenant de trois blogs cinÃ©matographiques anglophones distincts afin d'identifier des tendances sÃ©mantiques et structurelles.

Le projet suit le mÃªme cheminement que le cours de Web Mining, Ã  savoir :
1.**Collecte de donnÃ©es (Scraping) :** RÃ©cupÃ©ration automatique de corpus massifs (textes, notes, mÃ©tadonnÃ©es, casting).
2.**Text Mining :** A complÃ©ter quand nous arriverons Ã  cette Ã©tape.
3.**Link Analysis :** A complÃ©ter quand nous arriverons Ã  cette Ã©tape.

---

## ğŸ“‚ Structure du Projet

L'architecture respecte la sÃ©paration entre code source, donnÃ©es brutes et rÃ©sultats. Dans le but de faciliter la rÃ©plication des analyses.

```text
.
â”œâ”€â”€ src/                    # Code source Python
â”‚   â”œâ”€â”€ scraping            # Scripts de collecte des donnÃ©es (RogerEbert)
â”‚   â”œâ”€â”€ text-mining         # Scripts de transformation et d'analyse du contenu textuel des critiques
â”‚   â”œâ”€â”€ link-analysis       # Scripts de construction du graph et d'analyses des liens
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # DonnÃ©es brutes issues du scraping, text-mining et link-analysis (.csv/.xlsx)
â”‚   â”‚                       # Note : Ces fichiers ne sont pas versionnÃ©s sur GitHub (via .gitignore)
â”‚   â””â”€â”€ processed/          # DonnÃ©es nettoyÃ©es prÃªtes pour l'analyse
â”‚
â”œâ”€â”€ results/                # Graphiques, visualisations et rapports
â”œâ”€â”€ .gitignore              # Configuration des fichiers exclus (env, donnÃ©es lourdes)
â”œâ”€â”€ requirements.txt        # Liste des dÃ©pendances Python nÃ©cessaires
â””â”€â”€ README.md               # Documentation du projet
```

---

## ğŸš€ Guide d'Utilisation (Pipeline)

### 1. Installation

Assurez-vous d'avoir Python 3.9+ installÃ©. Clonez le repo et installez les dÃ©pendances :

```Bash
git clone https://github.com/votre-compte/votre-repo.git
cd votre-repo
pip install -r requirements.txt
```

### 2. ExÃ©cution des analyses

Pour rÃ©pliquer l'analyse complÃ¨te, exÃ©cutez les scripts dans l'ordre suivant :

* **Collecte :** `python src/scraping/scraper.py` (GÃ©nÃ¨re le fichier brut).

* **Traitement & Graphe :** `python src/text_mining/generate_gephi_linked.py` (GÃ©nÃ¨re les nÅ“uds et les arÃªtes).

* **Analyse des mÃ©triques :** `python src/link_analysis/link_analysis_numpy.py` (Calcule les centralitÃ©s matricielles).

---

## ğŸ§  MÃ©thodologie et Concepts ClÃ©s

### Text Mining

Nous utilisons une approche hybride combinant TF-IDF et Truncated SVD (Latent Semantic Analysis) pour regrouper les films par thÃ©matiques sÃ©mantiques de leur critique. Un nettoyage strict (suppression des noms propres et lemmatisation) garantit la pertinence des thÃ¨mes.

### Link Analysis (Approche Matricielle)

Contrairement aux approches classiques utilisant des librairies haut niveau, nous avons implÃ©mentÃ© les mesures de centralitÃ© via l'algÃ¨bre linÃ©aire :

* **CentralitÃ© de DegrÃ© :** CalculÃ©e via la matrice d'adjacence binaire.

* **PageRank :** ImplÃ©mentÃ© par la mÃ©thode des puissances (Power Iteration).

* **Information Centrality :** CalculÃ©e Ã  partir de la Pseudo-Inverse du Laplacien (L +) pour identifier les nÅ“uds ponts.

* **Closeness, Eccentricity & Shortest Path :** BasÃ©s sur l'algorithme de Floyd-Warshall.

## ğŸ“Š AperÃ§u des RÃ©sultats

### Visualisation Gephi

Mettre une image du graphe Gephi Final

*LÃ©gende* : Les couleurs reprÃ©sentent les thÃ¨mes (Clusters) identifiÃ©s par TF-IDF.

### Top Films (Link Analysis)

Voici un extrait des films les plus influents identifiÃ©s par nos algorithmes : Mettre ici une capture d'Ã©cran ou un petit tableau du rendu Tabulate.
