import pandas as pd
import numpy as np  # Indispensable pour le TF-IDF
from collections import Counter
import ast
import os


# CONFIGURATION

#dossier = r"C:\Users\33778\Desktop\WM (Amine)"
#chemin_entree = os.path.join(dossier, "resultat_avec_tokens.csv")
#chemin_sortie_tfidf = os.path.join(dossier, "matrice_vectorielle_tf-idf.csv")

# We go up to the file root 
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

chemin_entree = os.path.join(BASE_DIR, "data", "raw", "results_with_tokens.csv")
chemin_sortie_tfidf = os.path.join(BASE_DIR, "data", "raw", "vector_matrix_tf-idf.csv")

print(f"üìÇ Lecture de : {chemin_entree}")
print(f"üíæ Sauvegarde pr√©vue dans : {chemin_sortie_tfidf}")

print(f"Lecture du fichier : {chemin_entree}")

# 1. CHARGEMENT ROBUSTE (S√©curit√©)
print(f"Lecture du fichier : {chemin_entree}")
if not os.path.exists(chemin_entree):
    print("‚ùå ERREUR : Fichier introuvable.")
    exit()

try:
    df = pd.read_csv(chemin_entree, sep=';', encoding='utf-8-sig', engine='python', on_bad_lines='warn')
except:
    print("‚ö†Ô∏è Lecture UTF-8 √©chou√©e, tentative Windows-1252...")
    df = pd.read_csv(chemin_entree, sep=',', encoding='cp1252', engine='python', on_bad_lines='warn')

# 2. CONVERSION TEXTE -> LISTE
print("Conversion du texte en listes...")
df['tokens'] = df['tokens'].fillna("[]").apply(ast.literal_eval)

# GESTION DES IDENTIFIANTS 
print("\n--- Cr√©ation des Identifiants ---")

# On s'assure que tout est texte
df['film_year'] = df['film_year'].astype(str)
df['film_title'] = df['film_title'].astype(str)


def creer_id(row):
    titre = row['film_title'].strip()
    # Nettoyage de l'ann√©e (suppression du .0 et des espaces)
    annee = row['film_year'].replace('.0', '').strip()

    # R√àGLE SIMPLE : Si l'ann√©e existe -> "Titre (Ann√©e)"
    if annee and annee != '0' and annee.lower() != 'nan':
        return f"{titre} ({annee})"
    else:
        # Si pas d'ann√©e -> Titre_Ligne (pour ne pas √©craser par erreur)
        return f"{titre}_{row.name}"


# Application de l'ID
df['unique_id'] = df.apply(creer_id, axis=1)

# Cr√©ation du dictionnaire
documents = dict(zip(df['unique_id'], df['tokens']))

print(f"--> {len(documents)} documents uniques retenus (Doublons fusionn√©s).")


# CR√âATION DE LA MATRICE (BAG OF WORDS)


# √âTAPE 1 : VOCABULAIRE
print("\nConstruction du vocabulaire...")
vocabulary = set()
for liste_mots in documents.values():
    vocabulary.update(liste_mots)
print(f"--> {len(vocabulary)} mots uniques.")

# √âTAPE 2 : FR√âQUENCES
print("Comptage des fr√©quences...")
term_frequencies = {doc: Counter(tokens) for doc, tokens in documents.items()}

# √âTAPE 3 : MATRICE BRUTE
print("G√©n√©ration de la matrice brute...")
td_matrix = pd.DataFrame(
    {term: [term_frequencies[doc].get(term, 0) for doc in documents] for term in vocabulary},
    index=documents.keys()
).fillna(0)

# FILTRAGE (REQUIS AVANT LE TF-IDF)

print("\n--- R√©duction et Filtrage ---")

# Filtre Mots Rares (Min DF >= 2)
compteur_mots = (td_matrix > 0).sum(axis=0)
filtered_td_matrix = td_matrix.loc[:, compteur_mots >= 2]

# Filtre Mots Fr√©quents (Max DF < 50%)
seuil_max = len(documents) * 0.5
compteur_mots_2 = (filtered_td_matrix > 0).sum(axis=0)
filtered_td_matrix = filtered_td_matrix.loc[:, compteur_mots_2 < seuil_max]

print(f"--> Dimension apr√®s filtrage : {filtered_td_matrix.shape}")


# CALCUL TF-IDF (CODE DU PROFESSEUR)

print("\n--- Calcul du TF-IDF ---")

# 1. TF (Term Frequency)
row_sums = filtered_td_matrix.sum(axis=1)
tf = filtered_td_matrix.div(row_sums, axis=0)

# 2. IDF (Inverse Document Frequency)
df_count = (filtered_td_matrix > 0).sum(axis=0)
N = filtered_td_matrix.shape[0]
idf = np.log((N) / (df_count))

# 3. TF-IDF
tf_idf = tf.mul(idf, axis=1).fillna(0)


# SAUVEGARDE

print(f"\nSauvegarde : {chemin_sortie_tfidf}")
tf_idf.to_csv(chemin_sortie_tfidf, sep=';', encoding='utf-8-sig')
print("‚úÖ Termin√© ! (TF-IDF calcul√© et doublons √©cras√©s)")