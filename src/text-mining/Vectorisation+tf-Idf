import pandas as pd
import numpy as np  # Indispensable pour le TF-IDF
from collections import Counter
import ast
import os


# CONFIGURATION

dossier = r"C:\Users\33778\Desktop\WM (Amine)"
chemin_entree = os.path.join(dossier, "resultat_avec_tokens.csv")
chemin_sortie_tfidf = os.path.join(dossier, "matrice_vectorielle_tf-idf.csv")

# 1. CHARGEMENT ROBUSTE (Sécurité)
print(f"Lecture du fichier : {chemin_entree}")
if not os.path.exists(chemin_entree):
    print("❌ ERREUR : Fichier introuvable.")
    exit()

try:
    df = pd.read_csv(chemin_entree, sep=';', encoding='utf-8-sig', engine='python', on_bad_lines='warn')
except:
    print("⚠️ Lecture UTF-8 échouée, tentative Windows-1252...")
    df = pd.read_csv(chemin_entree, sep=',', encoding='cp1252', engine='python', on_bad_lines='warn')

# 2. CONVERSION TEXTE -> LISTE
print("Conversion du texte en listes...")
df['tokens'] = df['tokens'].fillna("[]").apply(ast.literal_eval)

# GESTION DES IDENTIFIANTS 
print("\n--- Création des Identifiants ---")

# On s'assure que tout est texte
df['film_year'] = df['film_year'].astype(str)
df['film_title'] = df['film_title'].astype(str)


def creer_id(row):
    titre = row['film_title'].strip()
    # Nettoyage de l'année (suppression du .0 et des espaces)
    annee = row['film_year'].replace('.0', '').strip()

    # RÈGLE SIMPLE : Si l'année existe -> "Titre (Année)"
    if annee and annee != '0' and annee.lower() != 'nan':
        return f"{titre} ({annee})"
    else:
        # Si pas d'année -> Titre_Ligne (pour ne pas écraser par erreur)
        return f"{titre}_{row.name}"


# Application de l'ID
df['unique_id'] = df.apply(creer_id, axis=1)

# Création du dictionnaire
documents = dict(zip(df['unique_id'], df['tokens']))

print(f"--> {len(documents)} documents uniques retenus (Doublons fusionnés).")


# CRÉATION DE LA MATRICE (BAG OF WORDS)


# ÉTAPE 1 : VOCABULAIRE
print("\nConstruction du vocabulaire...")
vocabulary = set()
for liste_mots in documents.values():
    vocabulary.update(liste_mots)
print(f"--> {len(vocabulary)} mots uniques.")

# ÉTAPE 2 : FRÉQUENCES
print("Comptage des fréquences...")
term_frequencies = {doc: Counter(tokens) for doc, tokens in documents.items()}

# ÉTAPE 3 : MATRICE BRUTE
print("Génération de la matrice brute...")
td_matrix = pd.DataFrame(
    {term: [term_frequencies[doc].get(term, 0) for doc in documents] for term in vocabulary},
    index=documents.keys()
).fillna(0)

# FILTRAGE (REQUIS AVANT LE TF-IDF)

print("\n--- Réduction et Filtrage ---")

# Filtre Mots Rares (Min DF >= 2)
compteur_mots = (td_matrix > 0).sum(axis=0)
filtered_td_matrix = td_matrix.loc[:, compteur_mots >= 2]

# Filtre Mots Fréquents (Max DF < 50%)
seuil_max = len(documents) * 0.5
compteur_mots_2 = (filtered_td_matrix > 0).sum(axis=0)
filtered_td_matrix = filtered_td_matrix.loc[:, compteur_mots_2 < seuil_max]

print(f"--> Dimension après filtrage : {filtered_td_matrix.shape}")


# CALCUL TF-IDF (CODE DU PROFESSEUR)

print("\n--- Calcul du TF-IDF ---")

# 1. TF (Term Frequency)
row_sums = filtered_td_matrix.sum(axis=1)
tf = filtered_td_matrix.div(row_sums, axis=0)

# 2. IDF (Inverse Document Frequency)
df_count = (filtered_td_matrix > 0).sum(axis=0)
N = filtered_td_matrix.shape[0]
idf = np.log((N) / (df_count))

# 3. TF-IDF
tf_idf = tf.mul(idf, axis=1).fillna(0)


# SAUVEGARDE

print(f"\nSauvegarde : {chemin_sortie_tfidf}")
tf_idf.to_csv(chemin_sortie_tfidf, sep=';', encoding='utf-8-sig')
print("✅ Terminé ! (TF-IDF calculé et doublons écrasés)")